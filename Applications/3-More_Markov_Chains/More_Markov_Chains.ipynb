{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NRJaggers/Applied-Stochastic-Processes/blob/main/Applications/3-More_Markov_Chains/More_Markov_Chains.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#More Markov Chains"
      ],
      "metadata": {
        "id": "lwN5bYfDW66u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Prompt"
      ],
      "metadata": {
        "id": "Bh1go0uHXDqq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original Prompt can be found [here](https://bookdown.org/kevin_davisross/applied-stochastic-processes/app-absorbing.html). A copy of the prompt along with the completed exercise can be found under [/Applications](https://github.com/NRJaggers/Applied-Stochastic-Processes/tree/main/Applications)."
      ],
      "metadata": {
        "id": "DJpcnN9AXHGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ],
      "metadata": {
        "id": "UPrX4PdRhz0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 1"
      ],
      "metadata": {
        "id": "NoBbPctjiBut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You roll a fair six-sided die 6 times. Whatever the results, you paint those on the sides of a blank die. So, if your rolls were 4, 5, 2, 6, 1, 1, then your new die has no 3’s and two 1’s. Then, you repeat the process with your new die — roll it 6 times and paint the results on a blank die. Eventually, you’ll roll the same number 6 times, at which point the process stops. Let $T$ = the number of rounds (of 6 rolls each) that you perform until stopping. (If your 6 rolls in the first round all result in the same number, then you stop with $T=1$.)"
      ],
      "metadata": {
        "id": "0z0QFPW_iQb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part 2"
      ],
      "metadata": {
        "id": "0gZVtEnGiDPm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part you will create and solve your own problems involving Markov chains. You have lots of flexibility, but your problems should include at least one part that requires:\n",
        "- A simulation\n",
        "- An analytical solution that uses either first step analysis/absorption\n",
        "- An analtyical solution that uses stationary distributions/long run behavior"
      ],
      "metadata": {
        "id": "PSJtYYnaiRJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Application - Part 1"
      ],
      "metadata": {
        "id": "GXUWHhYNXK3F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1."
      ],
      "metadata": {
        "id": "NnOccgJbXbpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code and run a simulation to approximate the distribution of $T$ and its expected value, without using Markov chains. Summarize the approximate distribution in an appropriate plot, and describe the distribution in 2-3 sentences (e.g., compute and interpret a few percentiles)."
      ],
      "metadata": {
        "id": "XM3D2LuSjI15"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2."
      ],
      "metadata": {
        "id": "MP7OWWO2jVdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a Markov chain that will help you find $E(T)$. Be sure to clearly define the state space. (Note: there are several ways to do this; any one is fine just be clear in your choice.)"
      ],
      "metadata": {
        "id": "kkJ1fAe3jXX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3."
      ],
      "metadata": {
        "id": "tA-1WvOWjXre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine the transition matrix for your Markov chain. You might want to compute a few of the transition probabilities by hand, but you’ll probably need to write code to fill in the whole matrix."
      ],
      "metadata": {
        "id": "u5_gkpvJjYPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4."
      ],
      "metadata": {
        "id": "Nq2oSIYHjY2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the transition matrix and tools from class to solve for $E(T)$. Compare to the simulated value from part 1."
      ],
      "metadata": {
        "id": "uqGHaW8sjZTd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5."
      ],
      "metadata": {
        "id": "wVB6Xfl3jZv0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the transition matrix and tools from class to solve for the distribution of $T$, and display the distribution in an appropriate plot. Compare to the simulated distribution from part 1."
      ],
      "metadata": {
        "id": "7q6YgLOZjaDy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## Application - Part 2"
      ],
      "metadata": {
        "id": "AdPqSeWRhMRE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKmTNU0WhOCh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}